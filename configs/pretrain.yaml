# ============================================================
# I-JEPA Pretraining Configuration
# ============================================================

# --- Data ---
data:
  processed_dir: "processed"
  unprocessed_dir: "unprocessed"
  image_size: [240, 320]       # H, W (native resolution)
  crop_size: 224               # square crop for ViT
  num_workers: 4

# --- Model (ViT-Small) ---
model:
  arch: "vit_small"
  patch_size: 16
  embed_dim: 384
  depth: 12
  num_heads: 6
  predictor_embed_dim: 192
  predictor_depth: 6
  predictor_num_heads: 6

# --- Masking ---
masking:
  num_targets: 4               # number of target blocks
  target_aspect_ratio: [0.75, 1.5]
  target_scale: [0.15, 0.2]   # fraction of patches per target
  context_aspect_ratio: 1.0
  context_scale: [0.85, 1.0]  # how much of the image the context sees

# --- Training ---
training:
  epochs: 300
  batch_size: 64
  base_lr: 1.5e-4
  weight_decay: 0.05
  warmup_epochs: 40
  min_lr: 1.0e-6
  clip_grad: 3.0
  
  # EMA for target encoder
  ema:
    start: 0.996
    end: 1.0

# --- Checkpointing ---
checkpoint:
  save_dir: "checkpoints"
  save_every: 50               # save every N epochs
  log_dir: "logs/pretrain"

# --- Misc ---
seed: 42
device: "cuda"
